# Paper Reading

## 1.作者信息

- **Linjun Zhang** 罗格斯大学

## 2.问题定义

​		在许多机器学习应用中，模型提供准确捕捉其预测不确定性的置信度分数非常重要。 尽管现代学习方法在预测准确性方面取得了巨大成功，但生成校准的置信度分数仍然是一项重大挑战。[深度学习的不确定性与校准](https://blog.csdn.net/xys430381_1/article/details/119531335)

​		Mixup 是一种流行但简单的数据增强技术，它基于训练示例对的凸组合，已根据经验发现可显着提高跨不同应用程序的置信度校准。 然而，Mixup 何时以及如何帮助校准仍然是一个谜。

## 3.相关工作

贡献

- 证明了Mixup带来的校准改进在高维设置中更为显著，即参数的数量与训练样本量相当。
- 研究了Mixup如何在半监督学习中帮助校准。
- 进一步将结果扩展到最大校准误差（MCE），这也显示了与ECE类似的现象。

相关工作

​		经验表明，Mixup 可以改善相同域和分布外域中深度神经网络的校准，我们的工作是第一次为这一现象提供理论解释。半监督学习是机器学习中的一个广泛领域，涉及从标记数据集和未标记数据集进行学习。 先前的工作主要集中在提高未标记数据的预测准确性和鲁棒性和对抗性鲁棒性 。最近发现未标记数据在一些实验中改善了贝叶斯不确定性校准，但使用未标记数据与校准之间的关系，特别是从理论角度来看，仍然很大程度上未知。 以上所有事实激发了我们在本文中的理论探索。

## 4.动机和思路

​		半监督学习是机器学习中的一个广泛领域，涉及从标记数据集和未标记数据集进行学习。 先前的工作主要集中在提高未标记数据的预测准确性和鲁棒性和对抗性鲁棒性 。最近发现未标记数据在一些实验中改善了贝叶斯不确定性校准，但使用未标记数据与校准之间的关系，特别是从理论角度来看，仍然很大程度上未知。 以上所有事实激发了我们在本文中的理论探索。

## 5.算法流程

**分类校准**：例如，给定1000个样本，每个样本的置信度为0.7，大约700个样本应该被正确地分类。

**Expected Calibration Error**(ECE)

最普遍的校准度量是预期校准误差（Naeini et al.，2015），其定义为：
$$
E C E=\mathbb{E}_{v \sim \mathcal{D}_{\hat{p}}}[|\mathbb{P}(\hat{y}=y \mid \hat{p}=v)-v|]
$$
**Maximum Calibration Error (MCE).**

另一个广泛使用的校准度量是最大校准误差（Naeini et al.，2015），其定义为
$$
M C E=\max _{v \in[0,1]}|\mathbb{P}(\hat{y}=y \mid \hat{p}=v)-v|
$$

### 监督学习中的校准

经验发现，在过度参数化的情况下或当参数数量和样本数量之间的比率 趋向于$0^+$ 时，使用 Mixup 对校准的改进

更为显着。

**The Gaussian model.**



## 6.实验结果

- 对于每个实验: (非常类似于我们自己做实验时所做的实验记录和实验报告)
  - 该实验讨论什么问题?
  - 实验设计是否合理? 能否很好地回答此问题?
  - 实验预期是什么? 结论是什么?
- 有哪些需要注意的实验细节? (数据处理? 参数等?)

## 7.源代码分析

- 如果作者提供了源代码, 我们需要对源代码进行阅读和分析, 应该回答如下问题:
  - 预期是否可以复现出作者的实验结果? 代码是否完整?
  - 对于某些特殊模块是怎么实现的? 可以示例核心代码.
  - 是否有一些实验细节文章中没有提及, 但是在代码中有体现的?